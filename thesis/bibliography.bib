@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018}
}

@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@COMMENT{
  #############################################
        Related Work (Distributed Deep RL)
  #############################################
} 

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and others},
  booktitle={Advances in neural information processing systems},
  pages={1223--1231},
  year={2012}
}

@article{ong2015distributed,
  title={Distributed deep Q-learning},
  author={Ong, Hao Yi and Chavez, Kevin and Hong, Augustus},
  journal={arXiv preprint arXiv:1508.04186},
  year={2015}
}

@article{nair2015massively,
  title={Massively parallel methods for deep reinforcement learning},
  author={Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and others},
  journal={arXiv preprint arXiv:1507.04296},
  year={2015}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{babaeizadeh2016ga3c,
  title={GA3C: GPU-based A3C for deep reinforcement learning},
  author={Babaeizadeh, Mohammad and Frosio, Iuri and Tyree, Stephen and Clemons, Jason and Kautz, Jan},
  journal={CoRR abs/1611.06256},
  year={2016}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@article{clemente2017efficient,
  title={Efficient parallel methods for deep reinforcement learning},
  author={Clemente, Alfredo V and Castej{\'o}n, Humberto N and Chandra, Arjun},
  journal={arXiv preprint arXiv:1705.04862},
  year={2017}
}

@inproceedings{adamski2018distributed,
  title={Distributed deep reinforcement learning: Learn how to play atari games in 21 minutes},
  author={Adamski, Igor and Adamski, Robert and Grel, Tomasz and J{\k{e}}drych, Adam and Kaczmarek, Kamil and Michalewski, Henryk},
  booktitle={International Conference on High Performance Computing},
  pages={370--388},
  year={2018},
  organization={Springer}
}

@article{horgan2018distributed,
  title={Distributed prioritized experience replay},
  author={Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and Van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1803.00933},
  year={2018}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}


@COMMENT{
  #############################################
              RL Frameworks
  #############################################
} 

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{juliani2018unity,
  title={Unity: A general platform for intelligent agents},
  author={Juliani, Arthur and Berges, Vincent-Pierre and Vckay, Esh and Gao, Yuan and Henry, Hunter and Mattar, Marwan and Lange, Danny},
  journal={arXiv preprint arXiv:1809.02627},
  year={2018}
}

@article{liang2017rllib,
  title={RLlib: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Moritz, Philipp and Nishihara, Robert and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph E and Jordan, Michael I and Stoica, Ion},
  journal={arXiv preprint arXiv:1712.09381},
  year={2017}
}

@article{castro2018dopamine,
  title={Dopamine: A research framework for deep reinforcement learning},
  author={Castro, Pablo Samuel and Moitra, Subhodeep and Gelada, Carles and Kumar, Saurabh and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1812.06110},
  year={2018}
}

@inproceedings{moritz2018ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 18)},
  pages={561--577},
  year={2018}
}


@COMMENT{
  #############################################
              Policy Search Ref. 
  #############################################
} 

@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and Trends{\textregistered} in Robotics},
  volume={2},
  number={1--2},
  pages={1--142},
  year={2013},
  publisher={Now Publishers, Inc.}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{fu2006gradient,
  title={Gradient estimation},
  author={Fu, Michael C},
  journal={Handbooks in operations research and management science},
  volume={13},
  pages={575--616},
  year={2006},
  publisher={Elsevier}
}

@article{glynn1990likelihood,
  title={Likelihood ratio gradient estimation for stochastic systems},
  author={Glynn, Peter W},
  journal={Communications of the ACM},
  volume={33},
  number={10},
  pages={75--84},
  year={1990},
  publisher={ACM}
}

@COMMENT{
  #############################################
                  Deep RL
  #############################################
} 

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{wang2018deep,
  title={Deep Reinforcement Learning for Autonomous Driving},
  author={Wang, Sen and Jia, Daoyuan and Weng, Xinshuo},
  journal={arXiv preprint arXiv:1811.11329},
  year={2018}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{singh2019end,
  title={End-to-End Robotic Reinforcement Learning without Reward Engineering},
  author={Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1904.07854},
  year={2019}
}


@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{heess2017emergence,
  title={Emergence of locomotion behaviours in rich environments},
  author={Heess, Nicolas and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, SM and Riedmiller, Martin and others},
  journal={arXiv preprint arXiv:1707.02286},
  year={2017}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@COMMENT{
  #############################################
              RL Applications
  #############################################
} 

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{mao2016resource,
  title={Resource management with deep reinforcement learning},
  author={Mao, Hongzi and Alizadeh, Mohammad and Menache, Ishai and Kandula, Srikanth},
  booktitle={Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
  pages={50--56},
  year={2016},
  organization={ACM}
}

@article{arel2010reinforcement,
  title={Reinforcement learning-based multi-agent system for network traffic signal control},
  author={Arel, Itamar and Liu, Cong and Urbanik, T and Kohls, AG},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={2},
  pages={128--135},
  year={2010},
  publisher={IET}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{bu2009reinforcement,
  title={A reinforcement learning approach to online web systems auto-configuration},
  author={Bu, Xiangping and Rao, Jia and Xu, Cheng-Zhong},
  booktitle={2009 29th IEEE International Conference on Distributed Computing Systems},
  pages={2--11},
  year={2009},
  organization={IEEE}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@inproceedings{xu2018zero,
  title={Zero-shot Deep Reinforcement Learning Driving Policy Transfer for Autonomous Vehicles based on Robust Control},
  author={Xu, Zhuo and Tang, Chen and Tomizuka, Masayoshi},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
  pages={2865--2871},
  year={2018},
  organization={IEEE}
}

@article{zhou2017optimizing,
  title={Optimizing chemical reactions with deep reinforcement learning},
  author={Zhou, Zhenpeng and Li, Xiaocheng and Zare, Richard N},
  journal={ACS central science},
  volume={3},
  number={12},
  pages={1337--1344},
  year={2017},
  publisher={ACS Publications}
}


@COMMENT{
  #############################################
                      Misc
  #############################################
} 

@inproceedings{recht2011hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in neural information processing systems},
  pages={693--701},
  year={2011}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@phdthesis{colome2011smooth,
  title={Smooth inverse kinematics algorithms for serial redundant robots},
  author={Colome, Adria},
  year={2011},
  school={Master Thesis, Institut de Robotica i Informatica Industrial (IRI~â€¦}
}

@inproceedings{chua2013robust,
  title={Robust optimal inverse kinematics with self-collision avoidance for a humanoid robot},
  author={Chua, Yuanwei and Tee, Keng Peng and Yan, Rui},
  booktitle={2013 IEEE RO-MAN},
  pages={496--502},
  year={2013},
  organization={IEEE}
}
